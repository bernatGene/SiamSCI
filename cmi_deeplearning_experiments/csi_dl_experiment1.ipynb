{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp1_csi_dl.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi4YWyJOw4aL"
      },
      "source": [
        "In this notebook we aim to reproduce the methods described in the paper: \"Camera model identification with the use of Deep Convolutional Neural Networks\" Tauma, A. et al 2016. However, we will try to use the Socrates dataset provided by Eurecom.\n",
        "\n",
        "Since this is a very preliminary test, we will download only a small sample of the dataset to ensure that the pipeline works.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVtQYhklx7-S"
      },
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEDkEZkwyHa1"
      },
      "source": [
        "We need to decide what the input size will be/How are we going to retrieve it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qmYH0TPyZiA"
      },
      "source": [
        "INPUT_SIZE = (256, 256, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6pBtIaOzRuD"
      },
      "source": [
        "#preprocessing, Define a sequential block to preprocess the input\n",
        "#Exact shape to be discussed, place-holder for now, we just rescale\n",
        "preprocessing = keras.Sequential(\n",
        "    [\n",
        "     layers.experimental.preprocessing.Rescaling(1./255)\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RflgLCu7yDwQ",
        "outputId": "131b6540-a34a-494b-ec17-8da214c0e22b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Define a model architecture based on their description \n",
        "def get_model(width=256, height=256, channels=3, num_classes=10):\n",
        "  inputs = keras.Input(shape=(width, height, channels))\n",
        "  x = preprocessing(inputs)\n",
        "  x = layers.Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), activation='relu') (x)\n",
        "  x = layers.Conv2D(filters=64, kernel_size=(3,3), strides=(2,2), activation='relu') (x)\n",
        "  x = layers.Conv2D(filters=32, kernel_size=(3,3), strides=(2,2), activation='relu') (x)\n",
        "  x = layers.MaxPooling2D(pool_size=(3,3), strides=(2,2) ) (x)\n",
        "  x = layers.Dense(256, activation='relu') (x)\n",
        "  x = layers.Dropout(0.2) (x)\n",
        "  x = layers.Dense(4096, activation='relu') (x)\n",
        "  x = layers.Dropout(0.2) (x)\n",
        "  outputs = layers.Dense(num_classes, activation='softmax') (x)\n",
        "  return keras.Model(inputs, outputs)\n",
        "\n",
        "model = get_model()\n",
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 256, 256, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 127, 127, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 63, 63, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 31, 31, 32)        18464     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 15, 15, 256)       8448      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 15, 15, 4096)      1052672   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 15, 15, 4096)      0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 15, 15, 10)        40970     \n",
            "=================================================================\n",
            "Total params: 1,159,274\n",
            "Trainable params: 1,159,274\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LXk22jy44OK"
      },
      "source": [
        "A priori, without having done any test, I am a bit skeptical about this model's architecure. It is an adaptation to AlexNet, which is a bit outdated, maybe other adaptations of more recent architectures may work much better"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYcawKS55M58"
      },
      "source": [
        "The next steps are to import a small subset of our data (to test the pipeline), contaning, for example, the images caputred by 10 different models. Of those, for each class, split the images into a train and val set, and perform a training to see if the pipeline works.\n",
        "\n",
        "**Summary of next steps**\n",
        "* Import a small subset of images\n",
        "* Decide how to preprocess the images so all have the same input size (Crop the center 256^2 pixels?)\n",
        "* Decide the preprocessing pipeline; in the paper they define a de-noising filter, it shouldn't be hard to implement.\n",
        "* Launch a training just to test the pipeline\n",
        "* Then, go back to analyzing the whole dataset structure, and decide on an input size, actual train and val sets, number of classes, etc.\n",
        "* Explore other architectures\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hGrBDvr5LAB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}