
%Reproducible

@article{FREIREOBREGON201986,
title = "Deep learning for source camera identification on mobile devices",
journal = "Pattern Recognition Letters",
volume = "126",
pages = "86 - 91",
year = "2019",
note = "Robustness, Security and Regulation Aspects in Current Biometric Systems",
issn = "0167-8655",
doi = "https://doi.org/10.1016/j.patrec.2018.01.005",
url = "http://www.sciencedirect.com/science/article/pii/S0167865518300059",
author = "David Freire-Obregón and Fabio Narducci and Silvio Barra and Modesto Castrillón-Santana",
keywords = "Source camera identification, Convolutional neural networks, Mobile devices, Deep learning",
abstract = "In the present paper, we propose a source camera identification (SCI) method for mobile devices based on deep learning. Recently, convolutional neural networks (CNNs) have shown a remarkable performance on several tasks such as image recognition, video analysis or natural language processing. A CNN consists on a set of layers where each layer is composed by a set of high pass filters which are applied all over the input image. This convolution process provides the unique ability to extract features automatically from data and to learn from those features. Our proposal describes a CNN architecture which is able to infer the noise pattern of mobile camera sensors (also known as camera fingerprint) with the aim at detecting and identifying not only the mobile device used to capture an image (with a 98% of accuracy), but also from which embedded camera the image was captured. More specifically, we provide an extensive analysis on the proposed architecture considering different configurations. The experiment has been carried out using the images captured from different mobile device cameras (MICHE-I Dataset) and the obtained results have proved the robustness of the proposed method."
}

@INPROCEEDINGS{7823908,
  author={A. {Tuama} and F. {Comby} and M. {Chaumont}},
  booktitle={2016 IEEE International Workshop on Information Forensics and Security (WIFS)}, 
  title={Camera model identification with the use of deep convolutional neural networks}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  abstract={In this paper, we propose a camera model identification method based on deep convolutional neural networks (CNNs). Unlike traditional methods, CNNs can automatically and simultaneously extract features and learn to classify during the learning process. A layer of preprocessing is added to the CNN model, and consists of a high pass filter which is applied to the input image. Before feeding the CNN, we examined the CNN model with two types of residuals. The convolution and classification are then processed inside the network. The CNN outputs an identification score for each camera model. Experimental comparison with a classical two steps machine learning approach shows that the proposed method can achieve significant detection performance. The well known object recognition CNN models, AlexNet and GoogleNet, are also examined.},
  keywords={cameras;convolution;feature extraction;high-pass filters;learning (artificial intelligence);neural nets;object recognition;camera model identification;deep convolutional neural networks;feature extraction;learning process classification;preprocessing layer;high pass filter;image;network convolution;machine learning;object recognition CNN models;AlexNet;GoogleNet;Cameras;Feature extraction;Neurons;Machine learning;Convolution;Biological neural networks;Image color analysis;Camera Identification;Deep Learning;Convolutional Neural Network;Fully Connected Network},
  doi={10.1109/WIFS.2016.7823908},
  ISSN={2157-4774},
  url = "https://ieeexplore.ieee.org/abstract/document/7823908"  
  month={Dec},}


%Interesting

@INPROCEEDINGS{8462383,  author={B. {Bayar} and M. C. {Stamm}},  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},   title={Towards Open Set Camera Model Identification Using a Deep Learning Framework},   year={2018},  volume={},  number={},  pages={2007-2011},  abstract={Existing forensic camera model identification algorithms can be trained to accurately distinguish between a set of known camera models. In reality, however, an investigator may be confronted with an image that was not captured by one of these known models. If this happens, existing algorithms will associate this image with one of the known camera models. This is known as the open set problem. In this paper, we propose two different approaches to address the open set problem for camera model identification. To do this, we use a CNN to learn a set of deep forensic features. Our first approach replaces the CNN's classifier with a confidence score mapping which it thresholds to detect unknown models. Our second approach uses a set of `known unknown' models to train a new classifier to identify unknown camera models. Experiments show that we can detect unknown camera models with a 97.74% accuracy.},  keywords={cameras;convolution;feature extraction;feedforward neural nets;image classification;learning (artificial intelligence);parameter estimation;deep learning framework;forensic camera model identification algorithms;deep forensic features;known unknown models;open set camera model identification;CNN's classifier;unknown camera models detection;Cameras;Forensics;Feature extraction;Computational modeling;Protocols;Data models;Measurement;Open set problem;camera model identification;deep convolutional features},  doi={10.1109/ICASSP.2018.8462383},  ISSN={2379-190X},  month={April}, url = "https://ieeexplore.ieee.org/abstract/document/8462383"}

@ARTICLE{8854834,  author={C. {Chen} and X. {Zhao} and M. C. {Stamm}},  journal={IEEE Transactions on Information Forensics and Security},   title={Generative Adversarial Attacks Against Deep-Learning-Based Camera Model Identification},   year={2019},  volume={},  number={},  pages={1-1},  abstract={Recently, deep learning techniques have gained popularity in multimedia forensics research designed to accomplish tasks such as camera model identification. However, despite the success of deep learning techniques, research has shown that they are vulnerable to adversarial perturbations. These adversarial perturbations can cause deep learning classifiers to misclassify images even though the perturbations are imperceptible to human eyes. To understand the vulnerabilities of deep-learning-based forensic algorithms, we propose a novel anti-forensic framework inspired by generative adversarial networks that is capable of falsifying an image’s source camera model. To accomplish this, we design a generator to anti-forensically falsify camera model traces in an image without introducing visually perceptible changes or artifacts. We propose two techniques to adversarially train this generator depending on the knowledge available to the attacker. In a white-box scenario when complete knowledge of an investigator’s camera model identification network is available to an attacker, we directly incorporate the network into our generator’s adversarial training strategy. In a black-box scenario when no internal details of the camera model classifier are available to the attacker, we construct a substitute network to mimic its decisions, then utilize this substitute network to adversarially train our generator. We conduct a series of experiments to evaluate the performance of our attack against several well-known CNNbased camera model classifiers. Experimental results show that our attack can successfully fool these CNNs in both white-box and black-box scenarios. Furthermore, our attack maintains high image quality and can be generalized to attack images from arbitrary source camera models.},  keywords={Cameras;Forensics;Generators;Training;Gallium nitride;Deep learning;Task analysis;Anti-forensics;Convolutional Neural Networks;Camera Model Identification;Generative Adversarial Network;White-box Attack;Black-box Attack;Substitute Network},  doi={10.1109/TIFS.2019.2945198},  ISSN={1556-6021},  month={}, url="https://ieeexplore.ieee.org/abstract/document/8854834"}

@INPROCEEDINGS{9035103,  author={M. {Kirchner} and C. {Johnson}},  booktitle={2019 IEEE International Workshop on Information Forensics and Security (WIFS)},   title={SPN-CNN: Boosting Sensor-Based Source Camera Attribution With Deep Learning},   year={2019},  volume={},  number={},  pages={1-6},  abstract={We explore means to advance source camera identification based on sensor noise in a data-driven framework. Our focus is on improving the sensor pattern noise (SPN) extraction from a single image at test time. Where existing works suppress nuisance content with denoising filters that are largely agnostic to the specific SPN signal of interest, we demonstrate that a deep learning approach can yield a more suitable extractor that leads to improved source attribution. A series of extensive experiments on various public datasets confirms the feasibility of our approach and its applicability to image manipulation localization and video source attribution. A critical discussion of potential pitfalls completes the text.},  keywords={cameras;feature extraction;image denoising;image sensors;learning (artificial intelligence);data-driven framework;sensor pattern noise extraction;single image;deep learning approach;suitable extractor;improved source attribution;image manipulation localization;video source attribution;SPN-CNN;boosting sensor-based source;source camera identification;sensor noise;nuisance content suppression;Cameras;Probes;Training;Maximum likelihood estimation;Noise reduction;Databases;Forensics},  doi={10.1109/WIFS47025.2019.9035103},  ISSN={2157-4774},  month={Dec}, url= "https://ieeexplore.ieee.org/abstract/document/9035103"}


 @misc{rosebrock _2020, title={Building image pairs for siamese networks with Python}, url={https://www.pyimagesearch.com/2020/11/23/building-image-pairs-for-siamese-networks-with-python/}, journal={PyImageSearch}, author={Rosebrock , Adrian}, year={2020}, month={Nov}
 }

@inproceedings{mayer_learned_2018,
	address = {Calgary, AB},
	title = {Learned {Forensic} {Source} {Similarity} for {Unknown} {Camera} {Models}},
	isbn = {9781538646588},
	url = {https://ieeexplore.ieee.org/document/8462585/},
	doi = {10.1109/ICASSP.2018.8462585},
	urldate = {2020-11-25},
	booktitle = {2018 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Mayer, Owen and Stamm, Matthew C.},
	month = apr,
	year = {2018},
	pages = {2012--2016},
}


