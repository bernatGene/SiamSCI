{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese network implementation with the strips dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random as rng\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_data = []\n",
    "with open('/home/data/strips_socrates/dataset_info.json') as json_file: \n",
    "    info_data = json.load(json_file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STRIP_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(info_data, batch_size, with_id=False, dataset = 'train'):\n",
    "    pairs = [np.zeros((batch_size, STRIP_SIZE, STRIP_SIZE, 3)) for i in range(2)]\n",
    "    labels = np.zeros((batch_size, ))\n",
    "    labels[batch_size//2:] = 1\n",
    "    split_index = int((len(info_data)-1) * 0.8)\n",
    "    if dataset == 'train':\n",
    "        students = [rng.randint(0, split_index) for _ in range(batch_size)] \n",
    "    elif dataset == 'whole':\n",
    "        students = [rng.randint(0, (len(info_data)-1)) for _ in range(batch_size)] \n",
    "    else:\n",
    "        students = [rng.randint(split_index+1, len(info_data)-1) for _ in range(batch_size)] \n",
    "    imgs = [rng.randint(0, len(info_data[i])-1) for i in students]\n",
    "    strips_loc = [rng.randint(0, len(info_data[i][0][1])-1) for i in students]\n",
    "    id_pairs = []\n",
    "    for i in range(batch_size):\n",
    "        std = students[i]\n",
    "        img = imgs[i]\n",
    "        srl = strips_loc[i]\n",
    "        strip1 = info_data[std][img][1][srl]\n",
    "        strip2 = \"\"\n",
    "        if i >= batch_size // 2:\n",
    "            img2 = (img + rng.randint(1, len(info_data[std])-1)) % len(info_data[std])\n",
    "            strip2 = info_data[std][img2][1][srl]\n",
    "        else:\n",
    "            std2 = (std + rng.randint(1, len(info_data)-1)) % len(info_data)\n",
    "            img2 = rng.randint(0, len(info_data[std2])-1)\n",
    "            srl2 = rng.randint(0, len(info_data[std2][0][1])-1)\n",
    "            strip2 = info_data[std2][img2][1][srl2]\n",
    "        pairs[0][i,:,:,:] = cv2.imread(strip1)/255\n",
    "        pairs[1][i,:,:,:] = cv2.imread(strip2)/255\n",
    "        id_pairs.append((strip1, strip2))\n",
    "    if with_id:\n",
    "        return pairs, labels, id_pairs\n",
    "    else:\n",
    "        return pairs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,l,ids = get_batch(info_data, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, ('/home/data/strips_socrates/111/Eurecom_111_picFG_007_256_1536.PNG', '/home/data/strips_socrates/126/Eurecom_126_picFG_004_2048_768.PNG'))\n",
      "(0.0, ('/home/data/strips_socrates/132/Eurecom_132_picFG_017_0_2560.PNG', '/home/data/strips_socrates/123/Eurecom_123_picFG_002_4096_512.PNG'))\n",
      "(0.0, ('/home/data/strips_socrates/140/Eurecom_140_picBG_030_768_1280.PNG', '/home/data/strips_socrates/113/Eurecom_113_picBG_005_2560_256.PNG'))\n",
      "(0.0, ('/home/data/strips_socrates/110/Eurecom_110_picBG_032_3328_2304.PNG', '/home/data/strips_socrates/126/Eurecom_126_picBG_023_768_1280.PNG'))\n",
      "(0.0, ('/home/data/strips_socrates/115/Eurecom_115_picBG_043_1280_1536.PNG', '/home/data/strips_socrates/139/Eurecom_139_picBG_043_256_512.PNG'))\n",
      "(1.0, ('/home/data/strips_socrates/118/Eurecom_118_picBG_021_1024_0.PNG', '/home/data/strips_socrates/118/Eurecom_118_picFG_040_1024_0.PNG'))\n",
      "(1.0, ('/home/data/strips_socrates/102/Eurecom_102_picBG_030_256_0.PNG', '/home/data/strips_socrates/102/Eurecom_102_picFG_039_256_0.PNG'))\n",
      "(1.0, ('/home/data/strips_socrates/143/Eurecom_143_picBG_006_2560_1536.PNG', '/home/data/strips_socrates/143/Eurecom_143_picBG_034_2560_1536.PNG'))\n",
      "(1.0, ('/home/data/strips_socrates/135/Eurecom_135_picBG_041_1024_1536.PNG', '/home/data/strips_socrates/135/Eurecom_135_picBG_011_1024_1536.PNG'))\n",
      "(1.0, ('/home/data/strips_socrates/115/Eurecom_115_picFG_036_256_0.PNG', '/home/data/strips_socrates/115/Eurecom_115_picFG_039_256_0.PNG'))\n"
     ]
    }
   ],
   "source": [
    "for x in zip(l, ids):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(info_data, batch_size, dataset='train'):\n",
    "    while True:\n",
    "        pairs, labels = get_batch(info_data, batch_size, False, dataset=dataset)\n",
    "        yield(pairs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_block(input_shape = (256,256,3), base_filters=64):\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.Conv2D(base_filters, (4,4), input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(base_filters*4, (5,5)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(base_filters*4, (5,5)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Conv2D(base_filters*4, (5,5)))\n",
    "    model.add(layers.Dense(base_filters*32, activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = sequential_block(base_filters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_siamese_model(input_shape = (256,256,3), base_filters=16):\n",
    "\n",
    "\n",
    "    left_input = layers.Input(input_shape)\n",
    "    right_input = layers.Input(input_shape)\n",
    "    \n",
    "    # Convolutional Neural Network\n",
    "    model = sequential_block(input_shape, base_filters)\n",
    "    \n",
    "    # Generate the encodings (feature vectors) for the two images\n",
    "    encoded_l = model(left_input)\n",
    "    encoded_r = model(right_input)\n",
    "    \n",
    "    # Add a customized layer to compute the absolute difference between the encodings\n",
    "    L1_layer = layers.Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "    L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "    # Add a dense layer with a sigmoid unit to generate the similarity score\n",
    "    prediction = layers.Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "    # Connect the inputs with the outputs\n",
    "    siamese_net = keras.Model(inputs=[left_input,right_input],outputs=prediction)\n",
    "    \n",
    "    # return the model\n",
    "    return siamese_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 294912)       265232      input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 294912)       0           sequential_1[0][0]               \n",
      "                                                                 sequential_1[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            294913      lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 560,145\n",
      "Trainable params: 559,857\n",
      "Non-trainable params: 288\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_siamese_model(base_filters=16)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr = 1e-4)\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 100\n",
    "steps_epoch = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "64/64 [==============================] - 35s 482ms/step - loss: 0.8581 - acc: 0.5176\n",
      "Epoch 2/100\n",
      "64/64 [==============================] - 31s 486ms/step - loss: 0.7036 - acc: 0.5378\n",
      "Epoch 3/100\n",
      "64/64 [==============================] - 31s 483ms/step - loss: 0.7040 - acc: 0.5314\n",
      "Epoch 4/100\n",
      "64/64 [==============================] - 31s 484ms/step - loss: 0.7035 - acc: 0.5264\n",
      "Epoch 5/100\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 0.6954 - acc: 0.5515\n",
      "Epoch 6/100\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 0.7055 - acc: 0.5186\n",
      "Epoch 7/100\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 0.6943 - acc: 0.5450\n",
      "Epoch 8/100\n",
      "64/64 [==============================] - 31s 485ms/step - loss: 0.6972 - acc: 0.5272\n",
      "Epoch 9/100\n",
      "64/64 [==============================] - 31s 486ms/step - loss: 0.7015 - acc: 0.5360\n",
      "Epoch 10/100\n",
      "64/64 [==============================] - 31s 486ms/step - loss: 0.6978 - acc: 0.5592\n",
      "Epoch 11/100\n",
      "64/64 [==============================] - 31s 487ms/step - loss: 0.6881 - acc: 0.5492\n",
      "Epoch 12/100\n",
      "64/64 [==============================] - 31s 487ms/step - loss: 0.7015 - acc: 0.5498\n",
      "Epoch 13/100\n",
      "64/64 [==============================] - 31s 486ms/step - loss: 0.6917 - acc: 0.5560\n",
      "Epoch 14/100\n",
      "64/64 [==============================] - 31s 486ms/step - loss: 0.6930 - acc: 0.5509\n",
      "Epoch 15/100\n",
      "64/64 [==============================] - 31s 486ms/step - loss: 0.6963 - acc: 0.5643\n",
      "Epoch 16/100\n",
      "64/64 [==============================] - 31s 487ms/step - loss: 0.7003 - acc: 0.5644\n",
      "Epoch 17/100\n",
      "64/64 [==============================] - 31s 487ms/step - loss: 0.6859 - acc: 0.5737\n",
      "Epoch 18/100\n",
      "64/64 [==============================] - 31s 487ms/step - loss: 0.6906 - acc: 0.5758\n",
      "Epoch 19/100\n",
      "64/64 [==============================] - 31s 488ms/step - loss: 0.6890 - acc: 0.5818\n",
      "Epoch 20/100\n",
      "64/64 [==============================] - 31s 488ms/step - loss: 0.6883 - acc: 0.5640\n",
      "Epoch 21/100\n",
      "64/64 [==============================] - 31s 488ms/step - loss: 0.6918 - acc: 0.5625\n",
      "Epoch 22/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6879 - acc: 0.5606\n",
      "Epoch 23/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6907 - acc: 0.5784\n",
      "Epoch 24/100\n",
      "64/64 [==============================] - 31s 488ms/step - loss: 0.6904 - acc: 0.5712\n",
      "Epoch 25/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6944 - acc: 0.5723\n",
      "Epoch 26/100\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.6932 - acc: 0.5815\n",
      "Epoch 27/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6951 - acc: 0.5764\n",
      "Epoch 28/100\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.6921 - acc: 0.5780\n",
      "Epoch 29/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6883 - acc: 0.5788\n",
      "Epoch 30/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6908 - acc: 0.5783\n",
      "Epoch 31/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6902 - acc: 0.5691\n",
      "Epoch 32/100\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.6967 - acc: 0.5634\n",
      "Epoch 33/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6935 - acc: 0.5700\n",
      "Epoch 34/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6926 - acc: 0.5769\n",
      "Epoch 35/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.7185 - acc: 0.5650\n",
      "Epoch 36/100\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.6825 - acc: 0.5991\n",
      "Epoch 37/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6782 - acc: 0.6081\n",
      "Epoch 38/100\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.6880 - acc: 0.5783\n",
      "Epoch 39/100\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.6807 - acc: 0.5908\n",
      "Epoch 40/100\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.6928 - acc: 0.5897\n",
      "Epoch 41/100\n",
      "64/64 [==============================] - 31s 489ms/step - loss: 0.6851 - acc: 0.5917\n",
      "Epoch 42/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6876 - acc: 0.5942\n",
      "Epoch 43/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6818 - acc: 0.5970\n",
      "Epoch 44/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6883 - acc: 0.5855\n",
      "Epoch 45/100\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.6885 - acc: 0.5996\n",
      "Epoch 46/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6830 - acc: 0.5923\n",
      "Epoch 47/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6793 - acc: 0.6016\n",
      "Epoch 48/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6931 - acc: 0.5931\n",
      "Epoch 49/100\n",
      "64/64 [==============================] - 31s 490ms/step - loss: 0.6772 - acc: 0.6047\n",
      "Epoch 50/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6825 - acc: 0.6126\n",
      "Epoch 51/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6946 - acc: 0.5958\n",
      "Epoch 52/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6919 - acc: 0.5996\n",
      "Epoch 53/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6943 - acc: 0.5932\n",
      "Epoch 54/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6809 - acc: 0.6035\n",
      "Epoch 55/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6863 - acc: 0.6070\n",
      "Epoch 56/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6791 - acc: 0.5997\n",
      "Epoch 57/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6923 - acc: 0.6090\n",
      "Epoch 58/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6782 - acc: 0.6127\n",
      "Epoch 59/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6922 - acc: 0.5944\n",
      "Epoch 60/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6805 - acc: 0.6039\n",
      "Epoch 61/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6851 - acc: 0.6005\n",
      "Epoch 62/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6826 - acc: 0.6174\n",
      "Epoch 63/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6927 - acc: 0.5919\n",
      "Epoch 64/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6778 - acc: 0.6142\n",
      "Epoch 65/100\n",
      "64/64 [==============================] - 32s 492ms/step - loss: 0.6837 - acc: 0.6083\n",
      "Epoch 66/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6819 - acc: 0.5939\n",
      "Epoch 67/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6657 - acc: 0.6354\n",
      "Epoch 68/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6897 - acc: 0.5942\n",
      "Epoch 69/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6783 - acc: 0.6020\n",
      "Epoch 70/100\n",
      "64/64 [==============================] - 32s 492ms/step - loss: 0.6752 - acc: 0.6100\n",
      "Epoch 71/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6817 - acc: 0.6041\n",
      "Epoch 72/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6860 - acc: 0.6031\n",
      "Epoch 73/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6843 - acc: 0.5999\n",
      "Epoch 74/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6897 - acc: 0.5998\n",
      "Epoch 75/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6776 - acc: 0.6149\n",
      "Epoch 76/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6832 - acc: 0.6017\n",
      "Epoch 77/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6865 - acc: 0.6151\n",
      "Epoch 78/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6734 - acc: 0.6090\n",
      "Epoch 79/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6766 - acc: 0.6079\n",
      "Epoch 80/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6836 - acc: 0.6056\n",
      "Epoch 81/100\n",
      "64/64 [==============================] - 32s 492ms/step - loss: 0.6780 - acc: 0.6010\n",
      "Epoch 82/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6800 - acc: 0.6042\n",
      "Epoch 83/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6717 - acc: 0.6131\n",
      "Epoch 84/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6820 - acc: 0.6161\n",
      "Epoch 85/100\n",
      "64/64 [==============================] - 32s 492ms/step - loss: 0.6715 - acc: 0.6247\n",
      "Epoch 86/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6800 - acc: 0.6068\n",
      "Epoch 87/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6664 - acc: 0.6294\n",
      "Epoch 88/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6711 - acc: 0.6135\n",
      "Epoch 89/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6970 - acc: 0.6005\n",
      "Epoch 90/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6652 - acc: 0.6274\n",
      "Epoch 91/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6769 - acc: 0.6106\n",
      "Epoch 92/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6794 - acc: 0.6078\n",
      "Epoch 93/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6732 - acc: 0.6076\n",
      "Epoch 94/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6822 - acc: 0.6121\n",
      "Epoch 95/100\n",
      "64/64 [==============================] - 32s 492ms/step - loss: 0.6958 - acc: 0.6003\n",
      "Epoch 96/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6688 - acc: 0.6272\n",
      "Epoch 97/100\n",
      "64/64 [==============================] - 31s 491ms/step - loss: 0.6692 - acc: 0.6266\n",
      "Epoch 98/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6879 - acc: 0.6067\n",
      "Epoch 99/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6685 - acc: 0.6311\n",
      "Epoch 100/100\n",
      "64/64 [==============================] - 31s 492ms/step - loss: 0.6694 - acc: 0.6130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4b3db5dc88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(generate(info_data, batch_size), \n",
    "         epochs = epochs,\n",
    "         steps_per_epoch= steps_epoch,\n",
    "         shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation:\n",
    "Simple, just feed pairs from the validation split and see the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extended validation:\n",
    "Take two images, and compare strip by strip, then do a majority voting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
